{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Overview Example\n",
    "\n",
    "- What it could look like\n",
    "- The final DataFrame could be stored in a csv file which can then be used in Excel other programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/konrad/programming/python/correlaid/datenguide-python\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datenguidepy.query_helper import get_all_regions, get_statistics\n",
    "from datenguidepy import Query\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "pd.set_option('display.max_colwidth', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BL = get_all_regions().query(\"level == 'nuts1'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_codes = BL.index.tolist()\n",
    "bl_names = BL.name.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a DataFrame with information - for 1 statistic\n",
    "- My idea was to cycle through different options and pull out only descriptive information from the run queries, to understand:\n",
    "    - the shape of resulting DataFrame\n",
    "    - the years containing information\n",
    "    - additional args available\n",
    "    - validity and periodicity\n",
    "- As the first step I started with pulling information for one statistic for all Bundesl√§nder\n",
    "- Then I ran into an issue with the dimensions\n",
    "\n",
    "<span style=\"color: blue\"> I think the idea is very good but would try to focus a little more on coverage. Which in turn would aim at methods specifically designed to give results for all regions and statistics. In order for this not to get too complicated I would reduce the descriptive information to begin with. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/konrad/programming/python/correlaid/datenguide-python/datenguidepy/output_transformer.py:130: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "  return pd.io.json.json_normalize(statistic_sub_json, sep=\"_\", max_level=1)\n"
     ]
    }
   ],
   "source": [
    "#create a list of df\n",
    "df_lst = []\n",
    "\n",
    "for bl in bl_codes:\n",
    "    bl_q = Query.region(str(bl))\n",
    "    bl_q.add_field('PLZ005')\n",
    "    \n",
    "    # create dataframe and store in a list\n",
    "    df_bl = bl_q.results()\n",
    "    df_lst.append(df_bl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Going through the DF\n",
    "rows_lst = []\n",
    "clmns_lst = []\n",
    "yr_min = []\n",
    "yr_max = []\n",
    "yr_diff = []\n",
    "s_valid = []\n",
    "s_period = []\n",
    "\n",
    "for df in df_lst:\n",
    "    # shape\n",
    "    rws = df.shape[0]\n",
    "    clmns = df.shape[1]\n",
    "    rows_lst.append(rws)\n",
    "    clmns_lst.append(clmns)\n",
    "    \n",
    "    #years\n",
    "    ymin = df.year.min()\n",
    "    ymax = df.year.max()\n",
    "    diff = ymax - ymin\n",
    "    yr_min.append(ymin)\n",
    "    yr_max.append(ymax)\n",
    "    yr_diff.append(diff)\n",
    "    \n",
    "    #source\n",
    "    valid = df.iat[0,5]\n",
    "    period = df.iat[0,6]\n",
    "    s_valid.append(valid)\n",
    "    s_period.append(period)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style = \"color: blue\">\n",
    "<h3> Suggestion for reduced statistics</h3>\n",
    "I recommend reduce the number of stored values for now. My suggestion is:\n",
    "    \n",
    "<ul>\n",
    "<li> Remove Columns as this is related to query building itself (I can add or remove columns)</li>\n",
    "<li> Without a Columns column I would rename Rows into Entries </li>\n",
    "<li> Eventually I would remove BL as a technichal overview does not require it and application and use cases can be build to reconstruct it from the Code</li>\n",
    "<li> I would \"Source valid from\" and \"Source periodicity\" as they are hard to put into perspective for a new user. </li>\n",
    "<li> I would add \"Number of distinct sources\" (as the unique number of source_names) as that might have direct user relevance (2 entries for one year)</li>\n",
    "<li> I would drop Total years for now for simplicity. The reason is that the number might easily be scewed when there are multiple sources for which one reports the statistic on a yearly basis and the other reports it for instance every 4 years. In simpler situations where there is not multiple sources per statistic, this number should be the same as Entries.</li>\n",
    "<li> Unlike the excel file, I would not include args/enums in the analysis yet for simplicity. Although this is potentially very interesting, these vary a lot across statistics and a I think I will be quite some further work to design and obtain a good overview for these. Also an analysis of these will possibly be easier in the near future when some of the enhancement issues have been implemented.</li>\n",
    "</ul>\n",
    "\n",
    "    \n",
    "In terms of analysis structure I recommend to create a function that calculates all the descriptive information for a single query result as a tuple or dictionary.\n",
    "When looping over several results this allows for easier collection of the results as a list of tuples/dicts which can be conveniently converted into a DataFrame\n",
    "    \n",
    "</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_result(region,statistic,query_result):\n",
    "    summary = {}\n",
    "    summary['region'] = region\n",
    "    summary['statistic'] = statistic\n",
    "    if not query_result.empty:\n",
    "        summary['region_name'] = query_result.name.iloc[0] #temporarily for convenience\n",
    "        summary['entries'] = query_result.shape[0]\n",
    "        summary['start_year'] = query_result.year.min()\n",
    "        summary['end_year'] = query_result.year.max()\n",
    "        summary['distinct_sources'] = query_result[f'{statistic}_source_name'].nunique()\n",
    "    else:\n",
    "        summary['entries'] = 0\n",
    "        # missing dict entries in this case will automatically\n",
    "        # create NaN entries when converted to a pandas DataFrame\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>BL</th>\n",
       "      <th>Statistic</th>\n",
       "      <th>Rows</th>\n",
       "      <th>Columns</th>\n",
       "      <th>Start year</th>\n",
       "      <th>End year</th>\n",
       "      <th>Total years</th>\n",
       "      <th>Source valid from</th>\n",
       "      <th>Source periodicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>Saarland</td>\n",
       "      <td>PLZ005</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>2007</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>1994-01-01T00:00:00</td>\n",
       "      <td>VIERJAEHRLICH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>PLZ005</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>2007</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>1994-01-01T00:00:00</td>\n",
       "      <td>VIERJAEHRLICH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>Brandenburg</td>\n",
       "      <td>PLZ005</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>2007</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>1994-01-01T00:00:00</td>\n",
       "      <td>VIERJAEHRLICH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>Mecklenburg-Vorpommern</td>\n",
       "      <td>PLZ005</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>2007</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>1994-01-01T00:00:00</td>\n",
       "      <td>VIERJAEHRLICH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>Sachsen</td>\n",
       "      <td>PLZ005</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>2007</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>1994-01-01T00:00:00</td>\n",
       "      <td>VIERJAEHRLICH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15</td>\n",
       "      <td>Sachsen-Anhalt</td>\n",
       "      <td>PLZ005</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>2007</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>1994-01-01T00:00:00</td>\n",
       "      <td>VIERJAEHRLICH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16</td>\n",
       "      <td>Th√ºringen</td>\n",
       "      <td>PLZ005</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>2007</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>1994-01-01T00:00:00</td>\n",
       "      <td>VIERJAEHRLICH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>01</td>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "      <td>PLZ005</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>2007</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>1994-01-01T00:00:00</td>\n",
       "      <td>VIERJAEHRLICH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>02</td>\n",
       "      <td>Hamburg</td>\n",
       "      <td>PLZ005</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>2007</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>1994-01-01T00:00:00</td>\n",
       "      <td>VIERJAEHRLICH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>03</td>\n",
       "      <td>Niedersachsen</td>\n",
       "      <td>PLZ005</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>2007</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>1994-01-01T00:00:00</td>\n",
       "      <td>VIERJAEHRLICH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>04</td>\n",
       "      <td>Bremen</td>\n",
       "      <td>PLZ005</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>2007</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>1994-01-01T00:00:00</td>\n",
       "      <td>VIERJAEHRLICH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>05</td>\n",
       "      <td>Nordrhein-Westfalen</td>\n",
       "      <td>PLZ005</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>2007</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>1994-01-01T00:00:00</td>\n",
       "      <td>VIERJAEHRLICH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>06</td>\n",
       "      <td>Hessen</td>\n",
       "      <td>PLZ005</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>2007</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>1994-01-01T00:00:00</td>\n",
       "      <td>VIERJAEHRLICH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>07</td>\n",
       "      <td>Rheinland-Pfalz</td>\n",
       "      <td>PLZ005</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>2007</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>1994-01-01T00:00:00</td>\n",
       "      <td>VIERJAEHRLICH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>08</td>\n",
       "      <td>Baden-W√ºrttemberg</td>\n",
       "      <td>PLZ005</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>2007</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>1994-01-01T00:00:00</td>\n",
       "      <td>VIERJAEHRLICH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>09</td>\n",
       "      <td>Bayern</td>\n",
       "      <td>PLZ005</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>2007</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>1994-01-01T00:00:00</td>\n",
       "      <td>VIERJAEHRLICH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Code                      BL Statistic  Rows  Columns  Start year  \\\n",
       "0    10                Saarland    PLZ005    25        9        2007   \n",
       "1    11                  Berlin    PLZ005    25        9        2007   \n",
       "2    12             Brandenburg    PLZ005    25        9        2007   \n",
       "3    13  Mecklenburg-Vorpommern    PLZ005    25        9        2007   \n",
       "4    14                 Sachsen    PLZ005    25        9        2007   \n",
       "5    15          Sachsen-Anhalt    PLZ005    25        9        2007   \n",
       "6    16               Th√ºringen    PLZ005    25        9        2007   \n",
       "7    01      Schleswig-Holstein    PLZ005    25        9        2007   \n",
       "8    02                 Hamburg    PLZ005    25        9        2007   \n",
       "9    03           Niedersachsen    PLZ005    25        9        2007   \n",
       "10   04                  Bremen    PLZ005    25        9        2007   \n",
       "11   05     Nordrhein-Westfalen    PLZ005    25        9        2007   \n",
       "12   06                  Hessen    PLZ005    25        9        2007   \n",
       "13   07         Rheinland-Pfalz    PLZ005    25        9        2007   \n",
       "14   08       Baden-W√ºrttemberg    PLZ005    25        9        2007   \n",
       "15   09                  Bayern    PLZ005    25        9        2007   \n",
       "\n",
       "    End year  Total years    Source valid from Source periodicity  \n",
       "0       2019           12  1994-01-01T00:00:00      VIERJAEHRLICH  \n",
       "1       2019           12  1994-01-01T00:00:00      VIERJAEHRLICH  \n",
       "2       2019           12  1994-01-01T00:00:00      VIERJAEHRLICH  \n",
       "3       2019           12  1994-01-01T00:00:00      VIERJAEHRLICH  \n",
       "4       2019           12  1994-01-01T00:00:00      VIERJAEHRLICH  \n",
       "5       2019           12  1994-01-01T00:00:00      VIERJAEHRLICH  \n",
       "6       2019           12  1994-01-01T00:00:00      VIERJAEHRLICH  \n",
       "7       2019           12  1994-01-01T00:00:00      VIERJAEHRLICH  \n",
       "8       2019           12  1994-01-01T00:00:00      VIERJAEHRLICH  \n",
       "9       2019           12  1994-01-01T00:00:00      VIERJAEHRLICH  \n",
       "10      2019           12  1994-01-01T00:00:00      VIERJAEHRLICH  \n",
       "11      2019           12  1994-01-01T00:00:00      VIERJAEHRLICH  \n",
       "12      2019           12  1994-01-01T00:00:00      VIERJAEHRLICH  \n",
       "13      2019           12  1994-01-01T00:00:00      VIERJAEHRLICH  \n",
       "14      2019           12  1994-01-01T00:00:00      VIERJAEHRLICH  \n",
       "15      2019           12  1994-01-01T00:00:00      VIERJAEHRLICH  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame ({'Code': bl_codes, 'BL': bl_names, 'Statistic': 'PLZ005', \n",
    "                          'Rows' : rows_lst, \n",
    "                          'Columns': clmns_lst,\n",
    "                          'Start year': yr_min,\n",
    "                          'End year' : yr_max,\n",
    "                          'Total years' : yr_diff,\n",
    "                          'Source valid from' : s_valid,\n",
    "                          'Source periodicity' : s_period\n",
    "                         })\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a DataFrame with information - for more statistics\n",
    "\n",
    "<span style=\"color: blue\"> \n",
    "<p> \n",
    "    I for one this seems to potentially have uncovered a bug in the underlying joining logic. Thats good and I'll try to folow up on it.\n",
    "    It seems to be related to TIE003 being empty at the same time when our package tries to join it with other data.\n",
    "</p>\n",
    "    \n",
    "<p>\n",
    "    Even when it works I don't think it is so important to join the different statsitics using our package functionality, as this will\n",
    "    skew row counts. One reason is the outer join character of the query functinality. The other reason is if a statistic has multiple\n",
    "    values during the same year, joining migh multiply the number of rows in total. When directly querying a statistic I don't think\n",
    "    the API should provide more than one value a year (if it works correctly), but it nonethelesse sometimes does. As in the case\n",
    "    of PLZ005 for instance. As such I reccomond creating a single query for every region,stat combination. See example blow.\n",
    "</p>\n",
    "</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random selection of stats for test run\n",
    "\n",
    "stats_lst = ['PLZ005','BEVSTD' ]# Works but not advisable\n",
    "# stats_lst = ['PLZ005', 'TIE003', 'BEVSTD' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/konrad/programming/python/correlaid/datenguide-python/datenguidepy/output_transformer.py:130: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "  return pd.io.json.json_normalize(statistic_sub_json, sep=\"_\", max_level=1)\n"
     ]
    }
   ],
   "source": [
    "# failed attempt to create a second list of DataFrames\n",
    "df_lst2 = []\n",
    "\n",
    "for bl in bl_codes:\n",
    "    bl_qu = Query.region(str(bl))\n",
    "    \n",
    "    for stat in stats_lst:\n",
    "        bl_qu.add_field(str(stat))\n",
    "        \n",
    "    \n",
    "    # create dataframe and store in a list\n",
    "    df_bl = bl_qu.results()\n",
    "    df_lst2.append(df_bl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a query for each combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>statistic</th>\n",
       "      <th>region_name</th>\n",
       "      <th>entries</th>\n",
       "      <th>start_year</th>\n",
       "      <th>end_year</th>\n",
       "      <th>distinct_sources</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>PLZ005</td>\n",
       "      <td>Saarland</td>\n",
       "      <td>25</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>TIE003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>BEVSTD</td>\n",
       "      <td>Saarland</td>\n",
       "      <td>31</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>PLZ005</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>25</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>TIE003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  region statistic region_name  entries  start_year  end_year  \\\n",
       "0     10    PLZ005    Saarland       25      2007.0    2019.0   \n",
       "1     10    TIE003         NaN        0         NaN       NaN   \n",
       "2     10    BEVSTD    Saarland       31      1995.0    2018.0   \n",
       "3     11    PLZ005      Berlin       25      2007.0    2019.0   \n",
       "4     11    TIE003         NaN        0         NaN       NaN   \n",
       "\n",
       "   distinct_sources  \n",
       "0               1.0  \n",
       "1               NaN  \n",
       "2               2.0  \n",
       "3               1.0  \n",
       "4               NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "stats_lst = ['PLZ005', 'TIE003', 'BEVSTD' ]\n",
    "\n",
    "query_summaries = []\n",
    "for region in bl_codes:\n",
    "    for stat in stats_lst:\n",
    "        q = Query.region(region)\n",
    "        q.add_field(stat)\n",
    "        query_result = q.results()\n",
    "        query_summaries.append(summarize_result(region,stat,query_result))\n",
    "        \n",
    "summary_frame = pd.DataFrame(query_summaries)\n",
    "summary_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: blue\">\n",
    "\n",
    "### Non datenguide related extra information\n",
    "\n",
    "A slightly more pythonian (although completely equivalent) way of dealing with nested for-loops is to use the `product` function from the `itertools` module. This is good practice for readability particularlrly when dealing with more then 2 nested loops. Therefore the following cell.\n",
    "\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/konrad/programming/python/correlaid/datenguide-python/datenguidepy/output_transformer.py:130: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "  return pd.io.json.json_normalize(statistic_sub_json, sep=\"_\", max_level=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>statistic</th>\n",
       "      <th>region_name</th>\n",
       "      <th>entries</th>\n",
       "      <th>start_year</th>\n",
       "      <th>end_year</th>\n",
       "      <th>distinct_sources</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>PLZ005</td>\n",
       "      <td>Saarland</td>\n",
       "      <td>25</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>TIE003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>BEVSTD</td>\n",
       "      <td>Saarland</td>\n",
       "      <td>31</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>PLZ005</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>25</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>TIE003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  region statistic region_name  entries  start_year  end_year  \\\n",
       "0     10    PLZ005    Saarland       25      2007.0    2019.0   \n",
       "1     10    TIE003         NaN        0         NaN       NaN   \n",
       "2     10    BEVSTD    Saarland       31      1995.0    2018.0   \n",
       "3     11    PLZ005      Berlin       25      2007.0    2019.0   \n",
       "4     11    TIE003         NaN        0         NaN       NaN   \n",
       "\n",
       "   distinct_sources  \n",
       "0               1.0  \n",
       "1               NaN  \n",
       "2               2.0  \n",
       "3               1.0  \n",
       "4               NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "query_summaries = []\n",
    "for region,stat in product(bl_codes,stats_lst):\n",
    "    q = Query.region(region)\n",
    "    q.add_field(stat)\n",
    "    query_result = q.results()\n",
    "    query_summaries.append(summarize_result(region,stat,query_result))\n",
    "        \n",
    "summary_frame = pd.DataFrame(query_summaries)\n",
    "summary_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: blue\">\n",
    "    \n",
    "## Suggested next steps\n",
    "\n",
    "The following next steps are suggested to deal with the problem that getting summaries for all statistics\n",
    "and regions will take very such that one will possibly not want to do it in a single go (possibly\n",
    "the datenguide API will also block as at one point due to too many requests in too short of a time).\n",
    "With the suggestions below one could summarize a subset of regions and statistics and pick up where\n",
    "one left of at a later point in time.\n",
    "    \n",
    "- writing summary information dataframe to disk\n",
    "- reading summary information dataframe from disk\n",
    "- append to existing summary dataframe information\n",
    "- condition summary calculation in the loop on summaries not already being present in summary information dataframe\n",
    "- optionally use the `Query.all_regions` function instead of the `Query.region` function. Although the returned results should not differ the former sends a single query to the API that can query several regions at once. This has the advanatage of reducing the API requests, in case this becomes an issue. It has the disadvantage that regions can only be specified indirectly by means of nuts level/lau and the parent region.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datenguide",
   "language": "python",
   "name": "datenguide"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
